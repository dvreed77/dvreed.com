[["Map",1,2,9,10,57,58],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.5.4","content-config-digest","502d11f956a42dd3","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":true,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[]},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"min-light\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"responsiveImages\":false,\"serializeConfig\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false},\"legacy\":{\"collections\":false}}","posts",["Map",11,12,21,22,30,31,39,40,48,49],"bayes",{"id":11,"data":13,"body":17,"filePath":18,"digest":19,"legacyId":20,"deferredRender":16},{"title":14,"date":15,"published":16},"Understanding Bayes Theorem","2021-02-14",true,"import {\n  SliderH,\n  SliderA,\n  SliderB,\n  Square1,\n  Square2,\n  Square3,\n  Divide,\n} from \"../../components/Ratio\";\n\nI've always found Bayes Theorem hard to understand. Even after semesters of studying probability you can eventually get the hang of the math involved, but developing a solid understanding of the real world implications can be challenging.\n\n## Breakdown\n\nThe standard formula you often see is:\n\n$$\nP(A|B) = \\frac{P(A)P(B|A)}{P(B)}\n$$\n\nIf we break up the formula, there are 4 parts, and 3 quantities that we need to find before we can get the answer.\n\n---\n\n$$\nP(A)\n$$\n\nThis is the probability of A happening not knowing anything else about the problem.\n\n---\n\n$$\nP(B)\n$$\n\nThis is the probability of B happening not knowing anything else about the problem. Sometimes its not possible to know this directly, but we can also find it based on this property:\n\n$$\nP(B) = P(A)P(B\\vert A) + P(\\bar{A})P(B\\vert \\bar{A})\n$$\n\n---\n\n$$\nP(B\\vert A)\n$$\n\nThis is the probability of B happening given that A has happened.\n\n---\n\n$$\nP(A\\vert B)\n$$\n\nThis is what we are trying find and in words, it can be described as:\n\n> What is the probability of seeing A given that we have seen B?\n\nor maybe:\n\n> What is the probability of A happening given what we know about B?\n\n---\n\n\u003Cdiv>\n## Visualize\n\nIt can help to visualize the probability as a large square that can be divided into portions. The square can largely be divided into the probability of hypothesis A happening, $P(\\textcolor{#d97706}{A})$ and the probability of A not happening, $P(\\textcolor{#059669}{\\bar{A}})$. These 2 events are obviously, mutually exclusive, and so the entire probability space is covered by these 2 events.\n\n\u003Cdiv class=\"sticky top-0 py-3 bg-white z-50 backdrop-blur backdrop-filter bg-opacity-75\">\n  \u003CSquare1 client:load />\n\u003C/div>\n\nLets adjust the probability of A happening, $P(A)$, and see how the probability space changes.\n\n\u003CSliderH client:load />\n\nThen, by looking only at the left, we can think about the probability of B happening given A, $P(B\\vert A)$, and the product of these 2 together give us the area of the square in the lower left corner.\n\n\u003CSliderA client:load />\n\n\u003CSquare2 client:load />\n\nWe can then look at the right to determine $P(B)P(B\\vert A)$.\n\n\u003CSliderB client:load />\n\n\u003CSquare3 client:load />\n\nWe now have everything we need to put these 3 quantities together to get the answer.\n\n\u003CDivide client:load />\n\u003C/div>\n---\n\n## Example\n\nYou find that a family member tested positive for a genetic defect. What are the odds they actually have the defect?\n\nThe doctor tells you that 1% of people have this certain genetic defect. He also tells you that 90% of tests for the gene detect the defect accurately and 9.6% of the tests give false positives.\n\nTake a moment to think how likely it is that your family member has the defect. You probably think that is very high, greater than 50% at least right?\n\nLets take this information and figure out the odds using Bayes Theorem.\n\n- $P(A)$ = 0.01\n- $P(B\\vert A)$ = 0.90\n- $P(B\\vert \\bar{A})$ = 0.096\n\n$P(A\\vert B)$ = (.9 * .01) / (.9 * .01 + .096 * .99) = 0.0865 (8.65%).\n\nThis is only an 8.65% chance that your family member has the defect. This is much lower than you probably thought.","src/content/posts/bayes.mdx","730fa4d1db51d3aa","bayes.mdx","thomson_sampling",{"id":21,"data":23,"body":26,"filePath":27,"digest":28,"legacyId":29,"deferredRender":16},{"title":24,"date":25,"published":16},"How Thomson Sampling can Optimize Email Send Times","2025-03-23","import { InteractiveBeta } from '../../components/InteractiveBeta';\nimport { ThompsonSamplingDemo } from '../../components/ThompsonSamplingDemo';\n\n\n## The Challenge: Timing is Everything\n\nImagine you're trying to reach a customer at the right time. Perhaps not everyone is ready to engage at 8 AM, when they're grabbing a coffee. What if some customers prefer a mid-morning buzz or even an early afternoon reminder? Instead of guessing the best time, we can use Thomson Sampling to find the optimal time.\n\n## Enter the Multi-Armed Bandit\n\nA multi-armed bandit is like a row of slot machines—each machine (or \"arm\") has its own, unknown payout rate. In my case, each hour of the day is an arm:\n- 6 AM might be great for some,\n- 8 AM was my default,\n- 10 AM might be even better, and so on.\n\nEvery time I send an email, I'm essentially \"pulling an arm.\" The reward? Whether a customer opens or clicks the email.\n\n## The Exploration vs. Exploitation Dilemma\n- Exploitation means sending emails at the time you currently believe works best.\n- Exploration means trying different hours to gather more data.\n\nThe goal is to strike a balance: learn which hour is best while still capitalizing on the best-known option.\n\n## Thompson Sampling: A Smart Way to Choose\n\nThomson Sampling is a strategy that balances exploration and exploitation by using a Beta distribution to model the uncertainty of the success rate for each hour.\n\n### 1. Starting with Complete Uncertainty\n\nFor each hour, we start with a Beta distribution with parameters α=1 and β=1. This represents complete uncertainty - it's saying we believe any success rate between 0 and 1 is equally likely:\n\n\u003CInteractiveBeta initialAlpha={1} initialBeta={1} client:load />\n\n### 2. Learning from Data\n\nAs we send emails and observe the results, we update our beliefs:\n- When someone opens an email (success), we add 1 to α\n- When someone doesn't open (failure), we add 1 to β\n\nFor example, let's say we sent 5 emails at 8 AM:\n- 3 people opened them (successes)\n- 2 didn't (failures)\n\nOur updated belief about 8 AM's success rate would look like this (α=4, β=3):\n\n\u003CInteractiveBeta initialAlpha={4} initialBeta={3} client:load />\n\nNotice how the distribution has:\n- Shifted to the right (because we saw more successes than failures)\n- Become narrower (because we have more data and thus more certainty)\n\n### 3. Making Decisions\n\nEach time we need to send an email:\n1. For each hour, we take a random sample from its Beta distribution\n2. We choose the hour with the highest sampled value\n\nThis naturally balances exploration and exploitation:\n- Hours with higher average success rates are chosen more often\n- Hours with wider distributions (more uncertainty) still have a chance to be picked\n- As we gather more data, the distributions narrow, and we focus more on the best performers\n\nHere's a live demonstration with 5 different hours after 10 experiments. Click \"Sample All Hours\" to see how Thompson Sampling makes its decision:\n\n\u003CThompsonSamplingDemo client:load />\n\nIn this visualization:\n- Each line represents the Beta distribution for a different hour\n- The dots show the random samples drawn from each distribution\n- The highest sampled value (highlighted) determines which hour to choose next\n\nNotice how:\n- 3 PM (15:00) has the highest success rate (peaked furthest right)\n- 6 PM (18:00) has the lowest success rate (peaked furthest left)\n- Hours with wider distributions have more uncertainty and thus more chance for exploration\n\nTry clicking \"Sample All Hours\" multiple times to see how the selection varies due to the random sampling, but tends to favor the better-performing hours.\n\n## Conclusion\n\nThomson Sampling is a powerful strategy for finding the optimal time to send emails. By using a Beta distribution to model the uncertainty of the success rate for each hour, we can balance exploration and exploitation to find the best time to send emails.","src/content/posts/thomson_sampling.mdx","053819f0fe443251","thomson_sampling.mdx","random_generators",{"id":30,"data":32,"body":35,"filePath":36,"digest":37,"legacyId":38,"deferredRender":16},{"title":33,"date":34,"published":16},"Random Noise Generators","2020-08-10","import { DistributionViewer } from \"../../components/DistributionViewer\";\n\nWhen you need to use randomness in your code, you only have a few tools at your disposal. Uniform sampling is built into Javascript with `Math.random()` and there are other libraries out there to get normally distributed random numbers, and more exotic distributions like Pareto, etc.\n\nWhat if you want to sample from something else, like a cubic function for example: $f(x) = x^3$? How do you that? The method required is called the [Inverse Transform Sampling Technique](https://en.wikipedia.org/wiki/Inverse_transform_sampling).\n\nFor a given probability function $f(x)$, if you integrate this function to get the cumulative distributions function $F(x)$, you can then sample uniformily on the y-axis and the corresponding x position will be sampled from the original function.\n\nIn the case of the commonly used probability functions, like Gaussian, etc, there is a nice closed form solution, but for other functions it makes more sense to do a lookup from samples of the CDF.\n\n# Process\n\nThe process is fairly simple:\n\n1. For the given Probability Density Function (PDF) $f(x)$, generate N samples\n2. Integrate the function to get the Cumulative Density Function (CDF) $F(x)$\n3. Generate a random variable $y$ from the uniform distribution and do a lookup of the corresponding $x$ value\n\n# Code\n\nHere is an example of how such a function could be implemented in TypeScript.\n\n```typescript\nexport function randomF(f: (x: number) => number, nPts = 1000) {\n  const dx = 1 / (nPts - 1);\n\n  const pdfData: [number, number][] = Array.from({\n    length: nPts,\n  }).map((_, idx) => [idx * dx, f(idx * dx)]);\n\n  const cdfData: [number, number][] = pdfData\n    .slice(1)\n    .reduce((a, b) => [...a, [b[0], a[a.length - 1][1] + dx * b[1]]], [[0, 0]]);\n\n  this.pdfData = pdfData;\n  this.cdfData = cdfData;\n\n  const maxD = Math.max(...cdfData.map((d) => d[1]));\n\n  return function () {\n    const x = Math.random() * maxD;\n    const idx = cdfData.findIndex((d) => d[1] > x);\n\n    return cdfData[idx][0];\n  };\n}\n```\n\n## Example Usage\n\nAnd here is how you could use that function to generate random samples from a cubic function:\n\n```typescript\nconst rGen = randomF((x) => x ** 3);\nconst sample = rGen();\n```\n\n# Examples\n\n## Uniform\n\n$$\nf(x) = 1\n$$\n\n\u003CDistributionViewer client:visible f=\"f1\" />\n\n## Gaussian\n\n\u003CDistributionViewer className=\"mb-5\" f=\"fGaussian\" client:visible />\n\n---\n\n## Linear\n\n$$\nf(x) = x\n$$\n\n\u003CDistributionViewer className=\"mb-5\" f=\"f2\" client:visible />\n\n---\n\n## Polynomials\n\n$$\nf(x) = x^3\n$$\n\n\u003CDistributionViewer className=\"mb-5\" f=\"f3\" client:visible />\n\n$$\nf(x) = x^3 + 0.2\n$$\n\n\u003CDistributionViewer className=\"mb-5\" f=\"f4\" client:visible />\n\n$$\nf(x) = x^2 + (1 - x)^{10}\n$$\n\n\u003CDistributionViewer className=\"mb-5\" f=\"f5\" client:visible />\n\n---\n\n## Pareto Distribution\n\n\u003CDistributionViewer className=\"mb-5\" f=\"f6\" client:visible />\n\n---\n\n## Sinusoids\n\n$$\nf(x) = 1 + \\cos(2\\pi x)\n$$\n\n\u003CDistributionViewer className=\"mb-5\" f=\"f7\" client:visible />\n\n$$\nf(x) = 1 + \\cos(2\\pi x + \\pi)\n$$\n\n\u003CDistributionViewer className=\"mb-5\" f=\"f8\" client:idle />","src/content/posts/random_generators.mdx","af55af49eb0ff4f9","random_generators.mdx","breweries",{"id":39,"data":41,"body":44,"filePath":45,"digest":46,"legacyId":47,"deferredRender":16},{"title":42,"date":43,"published":16},"Which US cities have the most breweries?","2018-08-10","import { SimpleTable, MapViewer } from \"../../components/SimpleTable\";\n\n\u003CMapViewer client:load />\n\u003CSimpleTable client:load />\n\n---\n\nI was recently having a discussion with a friend about which city had the most breweries. I couldn't find anything on the internet that was able to answer that simple question. I decided to use this as an opportunity for a little project.\n\n## Gather Data\n\nI decided to use BeerAdvocate as my source. I was almost certain there was an API for BeerAdvocate, but there wasn't, so I had to scrap their listings page, which was easy enough.\n\nI saved off the HTML files, so I didn't have to scrape more than I needed to.\n\n```python\nfor p in range(1510):\n    params = {\n        'start': 20*p,\n        'c_id': 'US'\n    }\n    page = requests.get('https://www.beeradvocate.com/place/list', params=params)\n\n    with open(f'./beer_advocate/page_{p}.html', 'w') as fid:\n        fid.write(str(page.content))\n```\n\nI then used lxml and some xpath magic to pull the relevant data.\n\n```python\nget_name = lambda x: x[0].xpath('./td[1]')[0].text_content()\nprint(get_name(p))\n\nget_address = lambda x: x[1].xpath(\"./td[1]/text()\")[0]\nprint(get_address(p))\n\nget_zip = lambda x: x[1].xpath(\"./td[1]/text()\")[2].split(', ')[1]\nprint(tryf(get_zip, p))\n\nget_city = lambda x: \" \".join(x[1].xpath(\"./td[1]/a[1]/text()\"))\nprint(tryf(get_city, p))\n\nget_state = lambda x: \" \".join(x[1].xpath(\"./td[1]/a[2]/text()\"))\nprint(tryf(get_state, p))\n\nget_country = lambda x: \" \".join(x[1].xpath(\"./td[1]/a[3]/text()\"))\nprint(tryf(get_country, p))\n\nget_score = lambda x: x[0].xpath('./td[2]')[0].text_content()\nprint(tryf(get_score, p))\n\nget_ratings = lambda x: x[0].xpath('./td[3]')[0].text_content()\nprint(tryf(get_ratings, p))\n\nget_beer_avg = lambda x: x[0].xpath('./td[4]')[0].text_content()\nprint(tryf(get_beer_avg, p))\n\nget_num_beers = lambda x: x[0].xpath('./td[5]')[0].text_content()\nprint(tryf(get_num_beers, p))\n```\n\nI then ran through all the files, pushing each brewery into a list and finally created a Pandas DataFrame.\n\n```python\nout = []\nfor page_num in range(1510):\n    page = get_page(page_num)\n    places = get_places(page)\n    for p in places:\n        out.append({\n            'name': get_name(p),\n            'address': tryf(get_address, p),\n            'city': tryf(get_city, p),\n            'state': tryf(get_state, p),\n            'country': tryf(get_country, p),\n            'zip': tryf(get_zip, p),\n            'score': get_score(p),\n            'ratings': get_ratings(p),\n            'beer_avg': get_beer_avg(p),\n            'num_beers': get_num_beers(p),\n        })\n\ndf = pd.DataFrame(out)\n```\n\nGetting the top 30 beer cities was as easy as ...\n\n```python\ndf[(df.num_beers != '-')].groupby(['city', 'state']).size().sort_values(ascending=False).head(30)\n```","src/content/posts/breweries.mdx","dd5e3aee00e2756b","breweries.mdx","math_test",{"id":48,"data":50,"body":53,"filePath":54,"digest":55,"legacyId":56,"deferredRender":16},{"title":51,"date":15,"published":52},"Math Test",false,"This is a test of math rendering.\n\nInline math: $f(x) = x^2$\n\nDisplay math:\n\n$$\nf(x) = \\int_0^x t^2 dt\n$$","src/content/posts/math_test.mdx","37bb630fa489d286","math_test.mdx","projects",["Map",59,60,74,75,89,90],"boston-landfill",{"id":59,"data":61,"body":70,"filePath":71,"digest":72,"legacyId":73,"deferredRender":16},{"title":62,"startDate":63,"endDate":64,"repoURL":65,"projectURL":66,"blurb":67,"images":68},"Boston Landfill","2017-10-06","2017-10-23","https://github.com/dvreed77/boston_landfill","https://dvreed77.github.io/boston_landfill/","An interactive visualization of the Boston Landfill",[69],"/assets/boston-landfill.png","This is a project I became interested in a long time ago. I have been in Boston for over 12 years, and knew that Boston was built over time from a series of landfill projects. I was interested in creating an app that allowed a user to scrub through time and see what parts of Boston were changed and when.\n\nAfter a little bit of digging, I found this dataset [here][1], an extremely poor quality GIF. I probably could have emailed the professor for something of higher quality, but since I am always up for a challenge, I wanted to use this to practice a variety of skills:\n\n- Understand GIFs in Python\n- Some basic image processing: dilation/erosion, thresholding, smoothing, etc.\n- Extract contours/shapes from an image\n- Shape manipulations: merging, intersection\n- SVG creation\n- GeoJSON creation\n- Interactive React App with GeoJSON objects\n- React App for timelines, and other Interactive elements\n\n[1]: http://www.bc.edu/bc_org/avp/cas/fnart/fa267/sequence.html\n[0]: http://scikit-image.org/docs/dev/auto_examples/xx_applications/plot_thresholding.html#bimodal-histogram\n\n## Data\n\nOriginal data was sourced here, a GIF image: http://www.bc.edu/bc_org/avp/cas/fnart/fa267/sequence.html\n\n![alt text](/assets/boston-landfill.gif \"Title\")\n\n## Key Lessons Learned\n\n### Read GIF in Python\n\nA colored GIF is just a `F x M x N x C` tensor, where `F` is the number of frames, `M` and `N` are the height and width, and `C=3` are the 3 RGB channels.\n\nEasy to read image (and make Greyscale):\n\n```python\nfrom skimage.io import imread\nfrom skimage.color import rgb2gray\n\nimage = rgb2gray(imread('img.gif'))\n```\n\n### Basic Image Processing\n\n#### Resizing\n\n```python\nfrom skimage.transform import resize as resize_image\n\nimage = resize_image(image, (1000, 1000))\n```\n\n#### Slight blur\n\n```python\nfrom skimage.filters import gaussian\n\nimage = gaussian(image, 2)\n```\n\n#### Thresholding\n\nI used `threshold_minimum` which is described as: The histogram of the input image is computed and smoothed until there are only two maxima. Then the minimum in between is the threshold value.\n\nIt is described in more detail [here][0]\n\n```python\nthreshold = threshold_minimum(rimage)\n\nbinary = (image > threshold).astype(int)\n  # binary = binary_dilation(binary)\n\n  return binary\n\n```\n\n#### Erosion/Dilation\n\n```python\nfrom skimage.morphology import binary_dilation, binary_erosion\n\nimage = binary_dilation(image)\n```\n\n### Get contours from image\n\nThis creates contours where image = 0. Since we created a binary image with thresholding, this is easy.\n\n```python\nfrom skimage import measure\n\ncontours = measure.find_contours(image, 0)\n```\n\n### Contour to Shapes\n\n```python\nfrom shapely.geometry import Polygon\n\npolygon = Polygon(c)\n```\n\n### Simplify shapes\n\n```python\np = polygon.simplify(0.5, preserve_topology=True)\n```\n\n### Convert contours to SVG\n\nIn order to convert Shapely shapes to SVG, I manually built my own SVG path elements, similar to this:\n\n```python\npath = svgwrite.path.Path()\next_points = list(shape.exterior.coords)\n\nP = [['M', int(ext_points[0][1]), int(ext_points[0][0])]] + [['L', int(x[1]), int(x[0])] for x in ext_points[1:]] + [['Z']]\n[path.push(*x) for x in P]\n\nfor interior in shape.interiors:\n    int_points = list(interior.coords)\n\n    P = [['M', int(int_points[0][1]), int(int_points[0][0])]] + [['L', int(x[1]), int(x[0])] for x in int_points[1:]] + [['Z']]\n    [path.push(*x) for x in P]\n```\n\n### Convert SVG to Polygons\n\nIn order to convert Shapely shapes to SVG, I manually built my own SVG path elements, similar to this:\n\n```python\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom xml.dom import minidom, Node\nfrom svg.path import parse_path as parse_svg_path\n\nsvg_doc = minidom.parse(\"data/svg_out.svg\")\n\ndef parse_path(path):\n    points = map(lambda x: (x.start.real, x.start.imag), parse_svg_path(path.getAttribute('d')))\n    return points\n\npoints = parse_path(svg_doc.getElementsByTagName(\"path\")[0])\nPolygon(points)\n```\n\n### Convert Polygons to GeoJSON\n\n```python\nfrom shapely.geometry import mapping\nimport json\n\nout = {\n    \"type\": \"FeatureCollection\",\n    \"features\": [\n        {\n            \"type\": \"Feature\",\n            \"properties\": { \"layer\": 5, \"region\": \"logan_airport\" },\n            \"geometry\": mapping(shape)\n        }\n    ]\n}\n\njson.dump(out, open('test.geojson', 'w'))\n\n```","src/content/projects/boston-landfill.mdx","bbb77fb482733925","boston-landfill.mdx","mortgage-calculator",{"id":74,"data":76,"body":85,"filePath":86,"digest":87,"legacyId":88,"deferredRender":16},{"title":77,"startDate":78,"endDate":79,"repoURL":80,"projectURL":81,"blurb":82,"images":83},"Mortgage Calculator","2019-11-06","2019-11-08","https://github.com/dvreed77/mortgage-calc","https://dvreed77.github.io/mortgage-calc","Interactive mortgage calculator",[84],"/assets/mortgage-calc.png","I recently purchased a house and was frustrated with the online mortage calculators I found online and so I created my own.","src/content/projects/mortgage-calculator.mdx","a62e9b1f1be906a7","mortgage-calculator.mdx","kmap",{"id":89,"data":91,"body":100,"filePath":101,"digest":102,"legacyId":103,"deferredRender":16},{"title":92,"startDate":93,"endDate":94,"repoURL":95,"projectURL":96,"blurb":97,"images":98},"Kisrhombille Tessellation","2019-12-15","2020-05-10","https://github.com/dvreed77/kmap","https://dvreed77.github.io/kmap","Shape building tool",[99],"/assets/kmap.png","In November of 2019, I participated in my first Codevember where I created generative art every day for the month of November. I was particularly intriqued by K Tessellation as described [here][1] by John Green.\n\nI wanted to create my own artwork, and was interested in developing my own drawing app to do this. This project is still a work in progress, but something I want to finish soon.\n\n[1]: https://github.com/johnalexandergreene/Geom_Kisrhombille/blob/master/README.md?utm_source=share&utm_medium=ios_app&utm_name=iossmf","src/content/projects/kmap.mdx","0fc150feece3a739","kmap.mdx"]